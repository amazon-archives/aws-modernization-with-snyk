[
{
	"uri": "http://localhost/50_conclusion/1_after_thoughts.html",
	"title": "Congratulations",
	"tags": [],
	"description": "",
	"content": " Well Done Congratulations. You have completed this DevSecOps workshop on shifting security testing left.\nRecap on what you have learned  Learned how to deploy CloudFormation stacks Learned about a modern CI/CD pipeline Learned how to test in AWS CodeBuild Learned about a couple of open source tools for security testing Learned why it is important to test as early as possible in the pipeline  Final Thoughts Due to the time and scope of the workshop there are several things that can and should be instrumented to improve security testing within the CI/CD pipeline. Here are a few suggestions to go above and beyond what you have learned in this workshop.\n Add notifications that provide feedback to developers using technology that developers are already familiar with and using. For build failures send to a slack channel, SMS, or email notifications using Amazon Simple Notification Service (SNS) and AWS Lambda. Use a branching method such as gitflow and test branches awaiting a pull request review. Utilize blue/green deployments to instrument additional security testing prior to production deployment. Enable git hooks to automate testing right when a developer commits code on her/his local machine. Add additional testing such as language specific linters, SAST, DAST, dependency CVE scanning, IAST, and RASP. Implementation should be similiar to what we accomplished in this workshop.  The sky\u0026rsquo;s the limit on adding additional features and functionality to DevSecOps. The point is to monitor your pipeline and continually make improvements to accelerate the release of features and functionality to your end customers.\nNext Steps Try and implement some of the learnings from the workshop on your company\u0026rsquo;s development process. Don\u0026rsquo;t try and do too much at one time and use an agile iterative approach. Remember that you are also trying to change culture by baking in security so don\u0026rsquo;t try and do too much too fast.\n"
},
{
	"uri": "http://localhost/10_prerequisites/1_aws_account.html",
	"title": "Create an AWS account",
	"tags": [],
	"description": "",
	"content": " Your account must have the ability to create new IAM roles and scope other IAM permissions.\n If you already have an AWS account, and have IAM Administrator access, you can skip this page.\n  If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "http://localhost/20_getting-started/1_getting_started.html",
	"title": "Creating your environment",
	"tags": [],
	"description": "",
	"content": " You are responsible for the cost of the AWS services used while running this workshop in your AWS account.\n In order for you to succeed in this workshop, you will need to run through a few steps in order to properly setup and configure your environment. These steps will include provisioning some services, installing some tools, and downloading some dependencies as well. We will begin with AWS Cloud9. Technically, you should be able to complete many of the steps in these modules if you have a properly configured terminal. However, in order to avoid the \u0026ldquo;works on my machine\u0026rdquo; response you\u0026rsquo;ve surely experienced at some point in your career, I strongly encourage you to proceed with launching Cloud9.\nAWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don’t need to install files or configure your development machine to start new projects.\n Deploy \u0026amp; Launch AWS Cloud9 Click here to deploy using CloudFormation template\n Create stack click, Next Specify stack details, click Next Configure stack options, click Next Review UnicornDevSecOpsWorkshop, scroll to bottom section under Capabilities and check both boxes and click Create stack   The deployment process takes approximately 2-3 minutes to complete. In the meantime, you can review the deployment guide while you wait.\n Once the installation is complete, go to Cloud9 within the console and click on Open IDE on the name that begins with WorkshopIDE.\nClone the source repository for this workshop Now we want to clone the repository that contains all the content and files you need to complete this workshop.\ncd ~/environment \u0026amp;\u0026amp; \\ git clone https://github.com/jamesbland123/workshop-sample modernization-workshop cd modernization-workshop git submodule init git submodule update Increase AWS Cloud9 disk/storage cd ~/environment/modernization-workshop/modules/20_getting_started ./resize.sh 50 Update and install some tools This step updates and installs various tools needed to complete the workshop. Feel free to look at the script if you are curious about what gets updated and installed.\n./getting_started.sh Next, lets source .bashrc to add .net PATH to our current working environment\n. ~/.bashrc"
},
{
	"uri": "http://localhost/",
	"title": "DevSecOps with Snyk",
	"tags": [],
	"description": "",
	"content": " DevSecOps with Snyk Welcome In this workshop, you will learn how to add security testing to a CI/CD pipeline of a dockerized application using AWS CodeCommit, AWS CodeBuild, and AWS CodePipeline. The modules contained in this workshop will provide you with step-by-step instructions for committing, building, testing, and deploying software in an automation fashion. You will also learn about some basic security tests and where to instrument them in the software development lifecycle. Objectives  Gain familiarity with the workflow of a modern application Learn where to add security testing to a CI/CD pipeline Learn about AWS services used to orchestrate testing  What we will cover in this workshop  Setup of a Cloud9 environment Usage of AWS CloudFormation to automate the deployment of infrastructure Deployment of Amazon Elastic Container Service Deploy and use a modenized pipeline using AWS CodePipeline, CodeCommit, and CodeBuild Instrument a couple of security testing/scanning tools  Sample reference architecture At the conclusion of this workshop, you will end up with various AWS services provisioned in your AWS account. The following diagram illustrates some of these services and is intended as a sample reference architecture. Workshop flow Each section or module contained in this workshop is designed to guide you through each step of the process to build the architecture referenced above. This is accomplished by using AWS Cloud 9 as our starting point along with a `git clone` of the content from our repository. Everything you need is provided to you including sample code, AWS CloudFormation templates, and detailed instructions. We will be using the AWS CLI from our Cloud9 instance to deploy the CloudFormation templates and build out our environment. The examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.  "
},
{
	"uri": "http://localhost/30_workshop_app_ci_cd/1_base_services.html",
	"title": "Setup Basic Services",
	"tags": [],
	"description": "",
	"content": " Introduction Up until now, we have been going through various steps to setup our environment. Installing tools and other necessary steps to make sure we progress through the modules without any issues. Now, we are ready to begin deploying the infrastructure that will support our Unicorn Store application.\nBasic Services CloudFormation Stack We are going to setup some basic services such as an AWS CodeCommit and Amazon ECR services.\nThis step takes approximately 2 minutes\n Copy and paste the following into Cloud9\u0026rsquo;s terminal to launch a CloudFormation stack\ncd ~/environment/modernization-workshop/modules/30_workshop_app aws cloudformation create-stack --stack-name WorkshopServices --template-body file://services.yaml --capabilities CAPABILITY_NAMED_IAM until [[ `aws cloudformation describe-stacks --stack-name \u0026#34;WorkshopServices\u0026#34; --query \u0026#34;Stacks[0].[StackStatus]\u0026#34; --output text` == \u0026#34;CREATE_COMPLETE\u0026#34; ]]; do echo \u0026#34;The stack is NOT in a state of CREATE_COMPLETE at `date`\u0026#34;; sleep 30; done \u0026amp;\u0026amp; echo \u0026#34;The Stack is built at `date` - Please proceed\u0026#34; The output should look like the window below  The stack is NOT in a state of CREATE_COMPLETE at Sun Sep 8 05:53:33 UTC 2019 The Stack is built at Sun Sep 8 05:54:04 UTC 2019 - Please proceed \n"
},
{
	"uri": "http://localhost/40_snyk/1_snyk.html",
	"title": "Snyk Security",
	"tags": [],
	"description": "",
	"content": " Snyk Security Expected Outcome  Install Snyk Test open source dependencies of the Petstore application, have it fail, remediate security issue, and then have it pass. Test a docker image for security vulnerabilities  Lab Requirements: Automation lab must be completed\nAverage Lab Time: 30 minutes\nIntroduction This module is designed to introduce scanning open source dependencies of the application and the Docker container that is created during this workshop. The files required for this module have already been created and reside in the /modules/snyk folder. You will copy these over while following the steps below.\nBackground Snyk is a SaaS offering that organizations use to find, fix, prevent and monitor open source dependencies. Snyk is a developer first platform that can be easily integrated into the Software Development Lifecycle (SDLC).\nAt this point of the module, the Petstore application is created, so we will look to insert Snyk as part of an important security gate during the build process.\nThis module will demonstrate how to fail a build when high severity issues are found so that remediation can take place.\nSnyk CLI The Snyk command line interface (CLI) has three key commands for this exercise: - snyk auth which links the CLI to your account and authorizes it to perform tests. - We will utilize Amazon\u0026rsquo;s System Manager Parameters to store this token to avoid hard-coding tokens. - Alternatively to using snyk auth, you can also set an environment variable SNYK_TOKEN which the CLI will automatically detect. - snyk test performs the actual test and can fail a build - snyk monitor posts a snapshot for continuous monitoring and reporting on the snyk.io interface where you created your account.\nTasks for this Lab For the purposes of this module, Snyk will be inserted into two key processes, when the application is being built, and when the Docker container is created.\nThis module has five sections: 1. Obtain a token for testing from https://snyk.io/ 2. Setting up application scanning 3. Setting up Docker analysis 4. Running a test and fixing the issue(s) detected 5. Viewing the status on the Snyk dashboard\nCreate a Snyk Account and Obtain a Token Obtain an account and setting up the credentials for this exercise:\n You will sign up to https://app.snyk.io/signup using Google, Bitbucket or Github credentials. Snyk utilizes these services for authentication and does not store passwords.   Once signed up you will navigate to your name (top right), and select Account Settings   Under API Token, click Show and copy this value, it will be unique for each user.   Clicking Show reveals the token to copy.  Save Password to Session Manager Run the following command, replacing abc123, with your unique token. This places the token in the session parameter manager.\naws ssm put-parameter --name \u0026quot;snykAuthToken\u0026quot; --value \u0026quot;abc123\u0026quot; --type SecureString  Setup the Application Scanning We want to insert testing with Snyk after maven has built the application. The simplest method is to insert commands to download, authorize and run the Snyk commands after Mvn has built the application/dependency tree.\nIn modules/snyk/Dockerfile, we have inserted the following commands to perform these actions\nSet an environment variable from a value passed to the docker build command, this will contain the token for Snyk. By using an environment variable, Snyk will automatically detect the token when used.\n#~~~~~~~SNYK Variable~~~~~~~~~~~~ # Declare Snyktoken as a build-arg ARG snyk_auth_token # Set the SNYK_TOKEN environment variable ENV SNYK_TOKEN=${snyk_auth_token} #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  Download Snyk, run a test, looking for medium to high severity issues, and if the build succeeds, post the results to Snyk for monitoring and reporting. If a new vulnerability is found, you will be notified.\n# package the application RUN mvn package -Dmaven.test.skip=true #~~~~~~~SNYK test~~~~~~~~~~~~ # download, configure and run snyk. Break build if vulns present, post results to `https://snyk.io/` RUN curl -Lo ./snyk \u0026quot;https://github.com/snyk/snyk/releases/download/v1.210.0/snyk-linux\u0026quot; RUN chmod -R +x ./snyk #Auth set through environment variable RUN ./snyk test --severity-threshold=medium RUN ./snyk monitor  Setting Up Docker Scanning Later in the build process, a docker image is created. We want to analyze it for vulnerabilities. We will do this in buildspec.yml. First, pull the Snyk token snykAuthToken from the parameter store:\nenv: parameter-store: SNYK_AUTH_TOKEN: \u0026quot;snykAuthToken\u0026quot;  In the prebuild phase, we will install Snyk\nphases: pre_build: commands: - PWDUTILS=$(pwd) - curl -Lo ./snyk \u0026quot;https://github.com/snyk/snyk/releases/download/v1.210.0/snyk-linux\u0026quot; - chmod -R +x ./snyk  In the build phase we will pass the token to the docker compose command where it will be retrieved in the Dockerfile code we previously setup to test the application:\nbuild: commands: - docker build --build-arg snyk_auth_token=$SNYK_AUTH_TOKEN -t $REPOSITORY_URI:latest .  Next we will authorize the Snyk instance for testing the Docker image that’s produced. If it passes we will pass the results to Snyk for monitoring and reporting.\nbuild: commands: - $PWDUTILS/snyk auth $SNYK_AUTH_TOKEN - $PWDUTILS/snyk test --docker $REPOSITORY_URI:latest - $PWDUTILS/snyk monitor --docker $REPOSITORY_URI:latest - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$IMAGE_TAG  In terminal, navigate to this folder:\ncd ~/environment/aws-modernization-workshop/  To try this module, let us copy the Snyk versions over to our build:\ncp modules/snyk/Dockerfile modules/containerize-application/Dockerfile cp modules/snyk/buildspec.yml buildspec.yml  Exercise - Testing In the Containerize Application lab you saw how to build your application. In this exercise you will try to run your build, which will fail due to security vulnerabilities being found. While normally done during the code development phase, we will take you through the process of fixing the vulnerability, and then re-running the exercise to see the build succeed.\nSave changes:\ngit commit -am \u0026quot;snyk\u0026quot;  Push:\ngit push -f codecommit master  Now in CodeBuild, look at your build history. Note it may take a minute or two for the new scan to run.\nLet’s look at why this failed. We see security vulnerabilities were found and we’re told how to fix it!\nTesting /usr/src/app... ✗ Medium severity vulnerability found in org.primefaces:primefaces Description: Cross-site Scripting (XSS) Info: https://snyk.io/vuln/SNYK-JAVA-ORGPRIMEFACES-31642 Introduced through: org.primefaces:primefaces@6.1 From: org.primefaces:primefaces@6.1 Remediation: Upgrade direct dependency org.primefaces:primefaces@6.1 to org.primefaces:primefaces@6.2 (triggers upgrades to org.primefaces:primefaces@6.2) ✗ Medium severity vulnerability found in org.primefaces:primefaces Description: Cross-site Scripting (XSS) Info: https://snyk.io/vuln/SNYK-JAVA-ORGPRIMEFACES-31643 Introduced through: org.primefaces:primefaces@6.1 From: org.primefaces:primefaces@6.1 Remediation: Upgrade direct dependency org.primefaces:primefaces@6.1 to org.primefaces:primefaces@6.2 (triggers upgrades to org.primefaces:primefaces@6.2) Organisation: sample-integrations Package manager: maven Target file: pom.xml Open source: no Project path: /usr/src/app Tested 37 dependencies for known vulnerabilities, found 2 vulnerabilities, 2 vulnerable paths. The command '/bin/sh -c ./snyk test' returned a non-zero code: 1 [Container] 2018/11/09 03:46:22 Command did not exit successfully docker build --build-arg snyk_auth_token=$SNYK_AUTH_TOKEN -t $REPOSITORY_URI:latest . exit status 1 [Container] 2018/11/09 03:46:22 Phase complete: BUILD Success: false [Container] 2018/11/09 03:46:22 Phase context status code: COMMAND_EXECUTION_ERROR Message: Error while executing command: docker build --build-arg snyk_auth_token=$SNYK_AUTH_TOKEN -t $REPOSITORY_URI:latest .. Reason: exit status 1  Exercise - Fixing the Vulnerability According to the remediation, we need to fix the PrimeFaces dependency and update it from version 6.1 to 6.2.\nLet us pretend the developer fixed it and checked it in, coming back into the pipeline. This is done by changing.\n~/environment/aws-modernization-workshop/modules/containerize-application/app/pom.xml\nChanging:\n\u0026lt;version.primefaces\u0026gt;6.1\u0026lt;/version.primefaces\u0026gt;  To:\n\u0026lt;version.primefaces\u0026gt;6.2\u0026lt;/version.primefaces\u0026gt;  Run this command to copy over our fixed version in the lab:\ncp modules/snyk/pom.xml modules/containerize-application/app/  Save changes:\ngit commit -am \u0026quot;Fix vulnerable open source dep.\u0026quot;  Push:\ngit push -f codecommit master  This time check Code Builder and we see it succeeded.\nTested 37 dependencies for known vulnerabilities, no vulnerable paths found. Next steps: - Run `snyk monitor` to be notified about new related vulnerabilities.  The vulnerability is fixed and the build succeeded!\nNext, we also see Snyk successfully scanned the Docker Image and there were no package dependency issues with our Docker container!\nContainer] 2018/11/09 03:54:14 Running command $PWDUTILS/snyk test --docker $REPOSITORY_URI:latest Testing 300326902600.dkr.ecr.us-west-2.amazonaws.com/petstore_frontend:latest... Organisation: sample-integrations Package manager: rpm Docker image: 300326902600.dkr.ecr.us-west-2.amazonaws.com/petstore_frontend:latest ✓ Tested 190 dependencies for known vulnerabilities, no vulnerable paths found.  Viewing Reporting  Navigate back to https://snyk.io/. You will see your Docker Image and Java application displayed Click View Report Set frequency project will be checked for vulnerabilities with the drop down list Click on View Report and then the Dependencies tab to see what libraries were used. Click View All Dependencies Use the Integrations tab (optionally) to connect and automate creation of fixes against a code repository.  "
},
{
	"uri": "http://localhost/30_workshop_app_ci_cd/10_push_to_repo.html",
	"title": "Build &amp; Push to Repo",
	"tags": [],
	"description": "",
	"content": " Build \u0026amp; Push to AWS CodeCommit We should now be ready to push our application to the AWS CodeCommit repo and the Amazon Elastic Container Repository\nThe following sets a new origin for the application repo to CodeCommit unicorn-store, configures a credential helper needed for CodeCommit, and pushes the source code to the repo. This step is necessary for an automated pipeline as CodeBuild will build the application directly from this repo.\ncd ~/environment/modernization-workshop/ git remote set-url origin https://git-codecommit.us-west-2.amazonaws.com/v1/repos/modernization-workshop git config --global credential.helper \u0026#39;!aws codecommit credential-helper $@\u0026#39; git config --global credential.UseHttpPath true git push origin master If successfully, you should see a similar message to the one below.\n  Counting objects: 9525, done. Compressing objects: 100% (5900/5900), done. Writing objects: 100% (9525/9525), 33.75 MiB | 2.65 MiB/s, done. Total 9525 (delta 3240), reused 9525 (delta 3240) remote: processing To https://git-codecommit.us-west-2.amazonaws.com/v1/repos/modernization-workshop * [new branch] master - master  Push to Amazon Elastic Container Repository (ECR) Now it\u0026rsquo;s time to compile and package your code. Copy and paste the below code into Cloud9\u0026rsquo;s terminal window\ncd ~/environment/modernization-workshop/app docker build -t modernization-workshop . docker tag modernization-workshop:latest $(aws ecr describe-repositories --repository-name modernization-workshop --query=repositories[0].repositoryUri --output=text):latest eval $(aws ecr get-login --no-include-email) docker push $(aws ecr describe-repositories --repository-name modernization-workshop --query=repositories[0].repositoryUri --output=text):latest If you watch the screen you should see the docker image build process animating the terminal\nIf successfully, you should see the message as below.\n  The push refers to repository [1234567891011.dkr.ecr.us-west-2.amazonaws.com/modernization-workshop] 8d2f7b95f78d: Pushed 82852e5eaa9d: Pushed 9df07df94e41: Pushed aa90bcce39de: Pushed d9ff549177a9: Pushed latest: digest: sha256:4229b5fe142f6d321ef2ce16ff22070e410272ee140e7eec51540a823dcd315a size: 1369  "
},
{
	"uri": "http://localhost/50_conclusion/10_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges.\nYou will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. With the CloudFormation Stacks, delete one at a time and validate the stack is removed before deleting the next stack.\n # Delete S3 Bucket aws s3 rm s3://$(aws s3api list-buckets --query \u0026#39;Buckets[?starts_with(Name, `workshoppipeline-artifactbucket`) == `true` ].Name\u0026#39; --output text) --recursive # Delete Log Group aws logs delete-log-group --log-group-name ModernizationWorkshop # Delete ECR Repository aws ecr delete-repository --repository-name modernization-workshop --force # Delete CloudFormation Pipeline and ECS Stacks aws cloudformation delete-stack --stack-name WorkshopPipeline aws cloudformation delete-stack --stack-name WorkshopECS Now remove the WorkshopServices stack\naws cloudformation delete-stack --stack-name WorkshopServices Finally, close the cloud9 window and manually verify deletion of previous stacks and delete the final stack. In the AWS console, go to CloudFormation. Ensure WorkshopPipeline, WorkshopECS, and WorkshopServices have all been removed. Once verified, click ModernizationWorkshop stack and then Delete\nVerify that none of the Workshop* stacks are listed in CloudFormation and you are done.\n"
},
{
	"uri": "http://localhost/10_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Prerequisites  Create an AWS account   "
},
{
	"uri": "http://localhost/30_workshop_app_ci_cd/20_ecs_fargate.html",
	"title": "Deploy ECS Fargate Service",
	"tags": [],
	"description": "",
	"content": " Deploy Fargate Service In the following set of commands we are going to use CloudFormation to deploy services that will allow our Unicorn Store application to service traffic from the Internet. The CloudFormation template sets up an ECS Cluster, a Service, Task Definition, Task, and Application Load Balancer.\ncd ~/environment/modernization-workshop/modules/30_workshop_app aws cloudformation create-stack --stack-name WorkshopECS --template-body file://ecs-fargate.yaml --capabilities CAPABILITY_NAMED_IAM until [[ `aws cloudformation describe-stacks --stack-name \u0026#34;WorkshopECS\u0026#34; --query \u0026#34;Stacks[0].[StackStatus]\u0026#34; --output text` == \u0026#34;CREATE_COMPLETE\u0026#34; ]]; do echo \u0026#34;The stack is NOT in a state of CREATE_COMPLETE at `date`\u0026#34;; sleep 30; done \u0026amp;\u0026amp; echo \u0026#34;The Stack is built at `date` - Please proceed\u0026#34; This step takes approximately 3 minutes and if successfully, you should see the message as below.\n  The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:34:25 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:34:55 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:35:26 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:35:57 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:36:27 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:36:58 UTC 2019 The Stack is built at Sun Aug 4 05:37:28 UTC 2019 - Please proceed  To test, run the following query and copy the URL you obtain from the output into the address bar of a web browser. You should see something similar to the image below.\naws elbv2 describe-load-balancers --names=\u0026#34;Modernization-Workshop-LB\u0026#34; --query=\u0026#34;LoadBalancers[0].DNSName\u0026#34; --output=text "
},
{
	"uri": "http://localhost/20_getting-started.html",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": " Getting Started  Creating your environment   "
},
{
	"uri": "http://localhost/30_workshop_app_ci_cd.html",
	"title": "Build and Deploy Sample App with CI/CD",
	"tags": [],
	"description": "",
	"content": " Build and Deploy Sample App with CI/CD  Setup Basic Services   Build \u0026amp; Push to Repo   Deploy ECS Fargate Service   Deploy CI/CD Pipeline   "
},
{
	"uri": "http://localhost/30_workshop_app_ci_cd/30_pipeline.html",
	"title": "Deploy CI/CD Pipeline",
	"tags": [],
	"description": "",
	"content": " What is CI/CD? Continuous integration (CI) and continuous delivery (CD) embodies a culture, set of operating principles, and collection of practices that enable application development teams to deliver features and functionality more frequently and reliably.\nContinuous integration is a coding philosophy and set of practices that drive development teams to implement small changes and check in code to version control repositories as frequently as possible. Because most modern applications require developing code in different platforms and tools, the team needs a mechanism to integrate and validate its changes.\nA goal of CI is to establish a consistent and automated way to build and test applications. With consistency in the integration process in place, teams are more likely to commit code changes more frequently, which leads to better collaboration and software quality through feedback loops.\nContinuous delivery picks up where continuous integration ends. CD automates the delivery of applications to selected infrastructure environments. Most teams work with multiple environments other than the production, such as development and testing environments, and CD ensures there is an automated way to push code changes to them. CD automation in a modern application performs any necessary deployment tasks while adhering to principles such as \u0026ldquo;infrastructure as code\u0026rdquo; and immutability.\nContinuous integration and delivery requires continuous testing because the objective is to deliver quality applications and code to users. Continuous testing is often implemented as a set of automated regression, performance, security, and other tests that are executed in the CI/CD pipeline.\nA mature CI/CD practice has the option of implementing continuous deployment where application changes run through the CI/CD pipeline and passing builds are deployed directly to production environments.\nCI/CD pipeline being deployed in this workshop  Development and local testing: The developer will work on coding tasks with the Cloud9 IDE environment. Once completed with the task the developer will commit her/his changes to the local git repository and test the changes. Push to remote master branch: When the developer is satisfied with the software changes, the developer will push those changes to the remote master branch. In this workshop this is the AWS CodeCommit Repo. AWS CodePipeline - Commit Event: CodePipeline will monitor AWS CodeCommit for any new commits. When a new commit (code change) is detected a CodeBuild job will be triggered. AWS CodePipeline - Build: Within CodeBuild a series of security tests will be instrumented to validate that code changes are not adding security risks to the application. If security issues are detect, this phase of the CodePipeline process is ended and the pipeline process reports a failure status. If no security issues are detected the build process continues by building and packaging the application. AWS CodePipeline - Postbuilld: Runs additional tests and if those test pass the container is pushed to Amazon ECR.\n AWS CodePipeline - Deploy: If the build process is successful, Codepipeline will update Elastic Container Service that there is a new image. The new image will be deployed and monitored. If all healthchecks pass the new deployment will become the primary service and the previous deployment will be gracefully shutdown. Monitor: ECS and the Application Load Balancer will continually monitor the health of the container and the application and will make the required adjustments to keep the minimum number of healthly container tasks running at all times.\n  Deploy CI/CD Pipeline To deploy the pipeline, run the following commands in Cloud9\u0026rsquo;s terminal\ncd ~/environment/modernization-workshop/modules/30_workshop_app aws cloudformation create-stack --stack-name WorkshopPipeline --template-body file://pipeline.yaml --capabilities CAPABILITY_NAMED_IAM until [[ `aws cloudformation describe-stacks --stack-name \u0026#34;WorkshopPipeline\u0026#34; --query \u0026#34;Stacks[0].[StackStatus]\u0026#34; --output text` == \u0026#34;CREATE_COMPLETE\u0026#34; ]]; do echo \u0026#34;The stack is NOT in a state of CREATE_COMPLETE at `date`\u0026#34;; sleep 30; done \u0026amp;\u0026amp; echo \u0026#34;The Stack is built at `date` - Please proceed\u0026#34; This step takes approximately 1 minute and if successfully, you should see the message as below.\n  The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:46:27 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:46:58 UTC 2019 The Stack is built at Sun Aug 4 05:47:29 UTC 2019 - Please proceed  At this point you should have a fully functioning CI/CD CodePipeline. If you head over to CodePipeline in the AWS console and click on the pipeline that begins with the name WorkshopPipeline-Pipeline you will see a similar screen to the one below.\n"
},
{
	"uri": "http://localhost/40_snyk.html",
	"title": "Snyk Security",
	"tags": [],
	"description": "",
	"content": " Snyk Security  Snyk Security   "
},
{
	"uri": "http://localhost/50_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": " Conclusion  Congratulations   Cleanup   "
},
{
	"uri": "http://localhost/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]